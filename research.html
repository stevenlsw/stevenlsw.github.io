<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script src="./research/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<style type="text/css">
    table {
        margin-bottom: 5px;
        margin-top: 5px;
    }
    body {
        font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight: 300;
        font-size: 18px;
        margin-left: auto;
        margin-right: auto;
        width: 60%;
    }

    h1 {
        font-weight: 300;
        font-size: 24px;
    }

    .disclaimerbox {
        background-color: #eee;
        border: 1px solid #eeeeee;
        border-radius: 10px;
        -moz-border-radius: 10px;
        -webkit-border-radius: 10px;
        padding: 20px;
    }

    video.header-vid {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px;
        -moz-border-radius: 10px;
        -webkit-border-radius: 10px;
    }

    img {
        width: 100%
    }

    img.header-img {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px;
        -moz-border-radius: 10px;
        -webkit-border-radius: 10px;
    }

    img.rounded {
        border: 1px solid #eeeeee;
        border-radius: 10px;
        -moz-border-radius: 10px;
        -webkit-border-radius: 10px;
    }

    a:link, a:visited {
        color: #1367a7;
        text-decoration: none;
    }

    a:hover {
        color: #208799;
    }

    td.dl-link {
        height: 160px;
        text-align: center;
        font-size: 22px;
    }

    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow: 0px 0px 1px 1px rgba(0, 0, 0, 0.35), /* The top layer shadow */ 5px 5px 0 0px #fff, /* The second layer */ 5px 5px 1px 1px rgba(0, 0, 0, 0.35), /* The second layer shadow */ 10px 10px 0 0px #fff, /* The third layer */ 10px 10px 1px 1px rgba(0, 0, 0, 0.35), /* The third layer shadow */ 15px 15px 0 0px #fff, /* The fourth layer */ 15px 15px 1px 1px rgba(0, 0, 0, 0.35), /* The fourth layer shadow */ 20px 20px 0 0px #fff, /* The fifth layer */ 20px 20px 1px 1px rgba(0, 0, 0, 0.35), /* The fifth layer shadow */ 25px 25px 0 0px #fff, /* The fifth layer */ 25px 25px 1px 1px rgba(0, 0, 0, 0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }


    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow: 0px 0px 1px 1px rgba(0, 0, 0, 0.35), /* The top layer shadow */ 5px 5px 0 0px #fff, /* The second layer */ 5px 5px 1px 1px rgba(0, 0, 0, 0.35), /* The second layer shadow */ 10px 10px 0 0px #fff, /* The third layer */ 10px 10px 1px 1px rgba(0, 0, 0, 0.35); /* The third layer shadow */
        margin-top: 5px;
        margin-left: 10px;
        margin-right: 30px;
        margin-bottom: 5px;
    }

    .vert-cent {
        position: relative;
        top: 50%;
        transform: translateY(-50%);
    }

    hr {
        border: 0;
        height: 1px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }


    #authors td {
        padding-bottom: 5px;
        padding-top: 30px;
    }
</style>

    <title>Research</title>
    <meta property="og:title" content="Research">
    <meta name="author" content="Shaowei">
    <link rel="icon" type="image/png" href="./index_files/icon.png">
</head>

<body>
    <header id="header">
        <span style="font-size:18px">
            <a href="index.html">Home</a>&nbsp;&nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;&nbsp;
            <a href="research.html">Research</a>&nbsp;&nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;&nbsp;
            <a href="project.html">Project</a>
        </span>
    </header>
<br>
<center>
    <span style="font-size:28px">Research</span>
 
<br><br>
<hr>
<center><h1>Semi-Supervised 3D Hand-Object Poses Estimation <br> with Interactions in Time</h1></center><table align="center">

    <table align=center>
        <tr>
            <td align=center>
                <center>
                    <span style="font-size:18px"><a href="https://drive.google.com/file/d/17FwKZcNxvmnOUYOJGijXISXkWFLboewv/view?usp=sharing"> [Paper]</a></span>
                </center>
            </td>
            <td align=center>
                <center>
                        <span style="font-size:18px"><a href='https://drive.google.com/file/d/135QJ6FcOWbNUb5rNiwR564z7nuDP3hZS/view?usp=sharing'> [Video]</a></span>
                </center>
            </td>
        </tr>
    </table>

</table>
</center>

<br>
Estimating 3D hand and object pose from a single image is an extremely challenging problem: 
hands and objects are often self-occluded during interactions, 
and the 3D annotations are scarce as even human cannot directly label the ground-truths from a single image perfectly. 
To tackle these challenges, we propose a unified framework for estimating the 3D hand and object poses with semi-supervised learning. 
We build a joint learning framework where we perform explicit contextual reasoning between hand and object representations. 
Going beyond limited 3D annotations in a single image, we leverage the spatial-temporal consistency in large-scale hand-object videos 
as a constraint for generating pseudo labels in semi-supervised learning. 
Our method not only improves hand pose estimation in challenging real-world dataset, 
but also substantially improve the object pose which has less ground-truths per instance. 
By training with large-scale diverse videos, our model also generalizes better across multiple out-of-domain datasets. 
<br>
<br>
<br>
<center><img src="./research/ho2021.png" align="middle"></center>
<br>
<hr>

<center><h1>Hand-Object Contact Consistency Reasoning <br> for Human Grasps Generation</h1></center><table align="center">

    <table align=center>
        <tr>
            <td align=center>
                <center>
                    <span style="font-size:18px"><a href="https://drive.google.com/file/d/1Gj6lPrqxrc7Csh37SDoseNoak711bsQf/view?usp=sharing"> [Paper]</a></span>
                </center>
            </td>
            <td align=center>
                <center>
                        <span style="font-size:18px"><a href='https://drive.google.com/file/d/1b5X78YwbGpWk1t42PueNcYgo6SOz8kXZ/view?usp=sharing'> [Video]</a></span>
                </center>
            </td>
        </tr>
    </table>

</table>
</center>

<br>
While predicting robot grasps with parallel jaw grippers have been well studied and widely applied in robot manipulation tasks, 
the study on natural human grasp generation with a multi-finger hand remains a very challenging problem. 
In this paper, we propose to generate human grasps given a 3D object in the world. 
Our key observation is that it is crucial to model the consistency between the hand contact points and object contact regions. 
That is, we encourage the prior hand contact points to be close to the object surface 
and the object common contact regions to be touched by the hand at the same time. 
Based on the hand-object contact consistency, we design novel objectives in training the human grasp generation model 
and also a new self-supervised task which allows the grasp generation network to be adjusted even during test time. 
Our experiments show significant improvement in human grasp generation over state-of-the-art approaches by a large margin. 
More interestingly, by optimizing the model during test time with the self-supervised task, 
it helps achieve larger gain on unseen and out-of-domain objects.
<br>
<br>
<br>
<center><img src="./research/affordance21.png" align="middle"></center>
<br>
<hr>

<center><h1>Robot Grasps from Video Demonstration</h1></center><table align="center">
</center>
<br>
Ongoing project, update soon. 

<br>
<br>
<br>
<center><img style="width:90%;max-width:90%" src="./research/manipulate2021.jpg" align="middle"></center>
</body></html>